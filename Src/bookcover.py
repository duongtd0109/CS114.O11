# -*- coding: utf-8 -*-
"""BookCover.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HPmkcgWsdf0j8ONu5xSe9vxqTP0ssfx0

# CS114.O11 - Machine Learning

Project: **Optical Character Recognition**

Application: *Bookshelf digitization*

### Members:

*   19521414 - Trịnh Đăng Dương
*   19522553 - Huỳnh Ngọc Hiệp Ý
*   21522123 - Phạm Quang Hưng

### Problem description
---
- **Input**: ảnh bìa sách định dạng .jpg.
- **Output**: thông tin trên bìa sách dạng văn bản bao gồm tiêu đề sách, tác giả, nhà xuất bản, các dòng chữ khác.
- **Ngữ cảnh ứng dụng**: nhập thông tin sách vào cơ sở dữ liệu của thư viện, tra cứu thông tin sách bằng hình ảnh

### Dataset
---
- **Xây dựng bộ dữ liệu**: tự chụp ảnh từ các thư viện, nhà sách gần nơi sinh sống và lấy ảnh bìa sách từ website Amazon.com
- Số lượng và độ đa dạng: bộ dữ liệu có **2000** ảnh bìa sách
- Phân chia (*split*) train / dev / test: 80% train, 10% dev, 10% test

### Feature
---
- Feature là các **pixel** trên ảnh chụp đã được tiền xử lý

### Algorithm
---
- **OCR**, or *Optical Character Recognition*, is a process of recognizing text inside images and converting it into an electronic form. These images could be of handwritten text, printed text like documents, receipts, name cards, etc., or even a natural scene photograph.

### References
- Analytics Vidhya (https://www.analyticsvidhya.com/blog/2020/05/build-your-own-ocr-google-tesseract-opencv/)
- TensorFlow (https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#configuring-a-training-pipeline)

# Setup
"""

#@title Mount Drive

from google.colab import drive
drive.mount('/content/drive')

# Link with the folder
!ln -s /content/drive/MyDrive/BookCover /content

# Commented out IPython magic to ensure Python compatibility.
#@title Get path of TensorFlow

# %tensorflow_version 2.x
import tensorflow as tf
import os

PART_OF_TF = os.path.dirname(os.path.abspath(tf.__file__))
print(f"Path to TensorFlow: {PART_OF_TF}")
print(tf.__version__)

!sudo pip install --upgrade tf_slim
# !pip install tensorflow-object-detection-api tensorflow_estimator tensorflow-addons

#@title Protobuf Installation/Compilation
!sudo apt update
!sudo apt install protobuf-compiler

!protoc --version
# From within TensorFlow/models/research/
!cd /content/BookCover/models/research/ && protoc object_detection/protos/*.proto --python_out=.

#@title COCO API installation
!git clone https://github.com/cocodataset/cocoapi.git
!cd cocoapi/PythonAPI && make
!cd cocoapi/PythonAPI && cp -r pycocotools /content/BookCover/models/research/

# Commented out IPython magic to ensure Python compatibility.
# #@title Install the Object Detection API (5min)
# 
# %%shell
# cd BookCover/models/research
# cp object_detection/packages/tf2/setup.py .
# python -m pip install .

#@title Test the installation

!cd BookCover/models/research && python object_detection/builders/model_builder_tf2_test.py

#@title Install TensorFlow object detection TF-TRT

!pip install tensorrt --extra-index-url https://pypi.nvidia.com

#@title Install TensorFlow 2.13.0 (15min)
!pip uninstall tensorflow
!pip install tensorflow==2.13.0

"""# Train the Model"""

# Commented out IPython magic to ensure Python compatibility.
#@title Start TensorBoard before training
!kill 97916
# %load_ext tensorboard
# %tensorboard --logdir=/content/drive/MyDrive/BookCover/models/faster_rcnn_inception_resnet_v2
# %tensorboard --logdir=/content/BookCover/models/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8
# %tensorboard --logdir=/content/BookCover/models/my_ssd_resnet50_v1_fpn

# %load_ext tensorboard
# %tensorboard --logdir logs

"""**Classification loss** được tính toán bằng cách so sánh kết quả dự đoán của mô hình với nhãn thực tế của dữ liệu.
$$L_c = - \sum_{i=1}^N y_i \log(p(y_i))$$
Trong đó:
*   $L_c$ là classification loss
*   $y_i$ là nhãn thực tế của dữ liệu thứ i
*   $p(y_i)$ là xác suất dự đoán của mô hình cho dữ liệu thứ i

**Localization loss** được tính toán bằng cách so sánh kết quả dự đoán của mô hình với vị trí thực tế của đối tượng. Hàm mất mát phổ biến nhất được sử dụng cho localization là **mean squared error**.
$$L_l = \frac{1}{N} \sum_{i=1}^N || x_i - \hat{x}_i ||^2$$
Trong đó:
*   $L_l$ là localization loss
*   $x_i$ là vị trí thực tế của đối tượng thứ $i$
*   $\hat{x}_i$ là kết quả dự đoán của mô hình cho vị trí của đối tượng thứ $i$

**Regularization loss** được tính toán bằng cách thêm một đại lượng vào hàm mất mát chính. Hàm mất mát phổ biến nhất được sử dụng cho regularization là L1 regularization và L2 regularization.
L1 được tính:
$$L_r = \lambda \sum_{j=1}^M |w_j|$$
L2 được tính:
$$L_r = \lambda \sum_{j=1}^M w_j^2$$
Trong đó:
*   $L_r$ là là regularization loss
*   $λ$ là hệ số regularization
*   $w_j$ là tham số thứ j của mô hình

**Total loss** là tổng của classification loss, localization loss và regularization loss. Total loss được tính theo công thức sau:
$$L_t = L_c + L_l + L_r$$
Trong đó:
*   $L_t$ là total loss
*   $L_c$ là classification loss
*   $L_l$ là localization loss
*   $L_r$ là regularization loss
"""

print(tf.__version__)

#@title Training the model

!python /content/BookCover/scripts/model_main_tf2.py \
      --model_dir=/content/BookCover/models/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8 \
      --pipeline_config_path=/content/BookCover/models/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config

from tensorboard import notebook
notebook.list() # View open TensorBoard instances

# Control TensorBoard display. If no port is provided,
# the most recently launched TensorBoard is used
notebook.display(port=6006, height=1000)

"""# Export the Model"""

import os
os.environ['PYTHONPATH'] += ':/content/BookCover/models/research/:/content/BookCover/models/research/slim/'

!pip install tensorflow_io tf-models-official

#@title Export the model
!python /content/BookCover/models/research/object_detection/exporter_main_v2.py \
    --input_type image_tensor \
    --pipeline_config_path /content/BookCover/models/my_ssd_resnet50_v1_fpn/pipeline.config \
    --trained_checkpoint_dir /content/BookCover/models/my_ssd_resnet50_v1_fpn/ \
    --output_directory /content/BookCover/exported-models/my_model_v3

"""## Fix bug"""

!sudo ln -s /usr/local/lib/python3.10/dist-packages/object_detection/core/ /content

# replace: slim = tf.contrib.slim
# to: slim = tf.compat.v1.estimator

# replace: from tensorflow.contrib.image.python.ops import image_ops
# to: from tensorflow.python.ops import image_ops

!unlink builders

!sudo ln -s /usr/local/lib/python3.10/dist-packages/object_detection/ /content

!tf_upgrade_v2 \
  --infile /content/BookCover/models/research/object_detection/exporter_main_v2.py \
  --outfile /content/BookCover/models/research/object_detection/exporter_main_v2_2.py

!tf_upgrade_v2 \
  --infile /content/example/mydata.py \
  --outfile /content/example/mydata2.py

!export PYTHONPATH=$PYTHONPATH:pwd:pwd/research:pwd/research/slim

"""# Demonstration"""

#@title Demo
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings

LABEL_FILENAME = 'label_map.pbtxt'
PATH_TO_LABELS = "/content/BookCover/annotations/label_map.pbtxt"
PATH_TO_MODEL_DIR = "/content/BookCover/exported-models/my_model_v3"
PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + "/saved_model"

import time
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils

def load_image_into_numpy_array(path):
    """Load an image from file into a numpy array.

    Puts image into numpy array to feed into tensorflow graph.
    Note that by convention we put it into a numpy array with shape
    (height, width, channels), where channels=3 for RGB.

    Args:
      path: the file path to the image

    Returns:
      uint8 numpy array with shape (img_height, img_width, 3)
    """
    return np.array(Image.open(path))

def download_images():
    base_url = "/content/BookCover/test/images/"
    image_paths = []
    files = os.listdir(base_url)
    for file in files:
      if file.endswith(".jpg"):
        image_paths.append(str(base_url + str(file)))
    return image_paths

IMAGE_PATHS = download_images()

print('Loading model...', end='')
start_time = time.time()

# Load saved model and build the detection function
detect_fn = tf.compat.v2.saved_model.load(PATH_TO_SAVED_MODEL, tags=None)

end_time = time.time()
elapsed_time = end_time - start_time
print('Done! Took {} seconds'.format(elapsed_time))

category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)

count=0
for image_path in IMAGE_PATHS:

    count += 1

    print('Running inference for {}... '.format(image_path), end='')

    image_np = load_image_into_numpy_array(image_path)

    # Things to try:
    # Flip horizontally
    # image_np = np.fliplr(image_np).copy()

    # Convert image to grayscale
    # image_np = np.tile(
    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)

    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
    input_tensor = tf.convert_to_tensor(image_np)
    # The model expects a batch of images, so add an axis with `tf.newaxis`.
    input_tensor = input_tensor[tf.newaxis, ...]

    # input_tensor = np.expand_dims(image_np, 0)
    detections = detect_fn(input_tensor)

    # All outputs are batches tensors.
    # Convert to numpy arrays, and take index [0] to remove the batch dimension.
    # We're only interested in the first num_detections.
    num_detections = int(detections.pop('num_detections'))
    detections = {key: value[0, :num_detections].numpy()
                   for key, value in detections.items()}
    detections['num_detections'] = num_detections

    # detection_classes should be ints.
    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)

    image_np_with_detections = image_np.copy()

    viz_utils.visualize_boxes_and_labels_on_image_array(
          image_np_with_detections,
          detections['detection_boxes'],
          detections['detection_classes'],
          detections['detection_scores'],
          category_index,
          use_normalized_coordinates=True,
          max_boxes_to_draw=200,
          min_score_thresh=.30,
          agnostic_mode=False)

    plt.figure()
    plt.imshow(image_np_with_detections)
    filename = "/content/BookCover/result_2/" + str(count) + ".jpg"
    plt.imsave(filename, image_np_with_detections)
    print('Done')

plt.show()

# sphinx_gallery_thumbnail_number = 2

plt.show()

# !unlink object_detection
# !ln -s /usr/local/lib/python3.10/dist-packages/object_detection/utils/label_map_util.py /content
# replace tf.gfile.* (line 132) to tf.io.gfile.*
# replace to tf.gfile.FastGFile

"""# Monitor using TensorBoard"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

import tensorflow as tf
import datetime, os

fashion_mnist = tf.keras.datasets.fashion_mnist

(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

def create_model():
  return tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28), name='layers_flatten'),
    tf.keras.layers.Dense(512, activation='relu', name='layers_dense'),
    tf.keras.layers.Dropout(0.2, name='layers_dropout'),
    tf.keras.layers.Dense(10, activation='softmax', name='layers_dense_2')
  ])

def train_model():

  model = create_model()
  model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])

  logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

  model.fit(x=x_train,
            y=y_train,
            epochs=5,
            validation_data=(x_test, y_test),
            callbacks=[tensorboard_callback])

train_model()

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

train_model()

from tensorboard import notebook
notebook.list() # View open TensorBoard instances

# Control TensorBoard display. If no port is provided,
# the most recently launched TensorBoard is used
notebook.display(port=6006, height=1000)

"""# For example"""

!python /content/BookCover/scripts/detector.py

!python /content/BookCover/scripts/detect_objects.py \
    --model_path /content/BookCover/pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model \
    --path_to_labelmap /content/BookCover/annotations/label_map.pbtxt \
    --images_dir /content/BookCover/test/images \
    --save_output \
    --output_dir /content/BookCover/test/result_v1